{
    "collab_server" : "",
    "contents" : "rm(list = ls())\ngc()\nlibrary(\"parallelMap\")\nlibrary(mlr)\nlibrary(sqldf)\nset.seed(42)\noptions(scipen = 999)\n\n#Installations necessary?\nif(FALSE){\n  install.packages(\"penalized\")\n  install.packages(\"C50\")\n  install.packages(\"randomForest\")\n  install.packages(\"adabag\")\n}\n\n\n#DATA IMPORT AND PREPARATION\noriginalDataImport = function(){\n  \n  train_org = read.csv2(\"joined_train_org_sample.csv\")\n  names(train_org)[names(train_org)==\"revenue\"] = \"revenue_Clean\"\n  \n  #Remove false predictors\n  train_org = subset(train_org, select = -c(X, pid, lineID))\n  \n  #factor data\n  train_org.factor = c(\"adFlag\", \"availability\", \"manufacturer\", \"group\", \"content\", \"unit\", \n                       \"genericProduct\", \"salesIndex\", \"category\", \"campaignIndex\")\n  \n  for(i in train_org.factor){\n    train_org[i] = as.factor(train_org[[i]])\n  }\n  \n  return(train_org)\n}\nprepDataImport = function(){\n  train = read.csv(\"mergedTrain_sample.csv\")\n  \n  names(train)[names(train)==\"order_Clean\"] = \"order\"\n  \n  #Remove false predictors\n  train = subset(train, select = -c(X, pid_Clean, lineID))\n  \n  #WEEKDAYS ARE MISSING\n  train.factor_fix = c(\"adFlag_Clean\", \"availability_Clean\", \"pharmForm_Clean\", \n                       \"genericProduct_Clean\", \"salesIndex_Clean\", \"missingCompetitorPrice\", \"weekdays\")\n  \n  train.factor_rem = c(\"manufacturer_Clean\", \"group_Clean\", \"content_Clean\", \"unit_Clean\", \"category_Clean\", \"campaignIndex_Clean\")\n  \n  train.factor = c(train.factor_fix, train.factor_rem)\n  \n  for(i in train.factor){\n    train[i] = as.factor(train[[i]])\n  }\n  \n  return(train)\n}\nsets = list(originalDataImport(), prepDataImport())\n\nremoveIDLikeFactors = function(listSets, maxNrFactors){\n  #Remove all factorial attributes with nr(factors) > 50\n  for(i in c(1:length(listSets))){\n    test = colnames(listSets[[i]][, sapply(listSets[[i]], is.factor)])\n\n    rem = c(NULL)\n    for(j in test){\n      if(length(table(listSets[[i]][j])) > maxNrFactors)\n        rem = c(rem, j)\n    }\n    \n    listSets[[i]] = listSets[[i]][, (! colnames(listSets[[i]]) %in% rem)]\n  }\n  \n  \n  return(listSets)\n}\nsets = removeIDLikeFactors(sets, 50)\n\n#MODEL PREPARATION\nrdesc = makeResampleDesc(\"CV\", iters = 3)\n#learner selection\nlearners = list(makeLearner(\"classif.OneR\"))\n\n#makeFeatSelWrapper(\"classif.C50\", resampling = rdesc, control = makeFeatSelControlGA(maxit = 10, mutation.rate = 0.1))\n\n#makeLearner(\"classif.boosting\")\n#makeFeatSelWrapper(\"classif.randomForest\", resampling = rdesc, control = makeFeatSelControlGA(maxit = 10, mutation.rate = 0.1))\n\n#parameter_sets if necessary\n#getParamSet(\"classif.penalized.lasso\")\n#lasso.learner = makeLearner(\"classif.penalized.lasso\")\n#lasso.learner = setHyperPars(lasso.learner, lambda1 = 10, trace = TRUE)\n#lasso.wrapper = makeFeatSelWrapper(lasso.learner, resampling = rdesc, control = makeFeatSelControlGA(maxit = 10, mutation.rate = 0.1))\n\n#learners = append(learners, list(lasso.wrapper))\n\n#make tasks\nmakeClassifTasks = function(listSets, target, rem = NULL){\n  tasks = list()\n  \n  for(i in c(1:length(listSets))){\n    tasks = append(tasks, list(makeClassifTask(id = as.character(i), data = subset(listSets[[i]], select = -c(quantity, revenue_Clean)), target = target)))\n  }\n  \n  return(tasks)\n}\n\n#Remove quantity for prediction\ntasks = makeClassifTasks(sets, \"order\")\n\n#RESAMPLING / TESTING DECSISION\nrdesc2 = makeResampleDesc(\"CV\", iters = 5)\n\n#EVALUATION\n#parralization\n#parallelStartBatchJobs()\nparallelStartSocket(2, level = \"mlr.resample\")\n#Setting up a benchmarking experiment\n\nbmr = benchmark(learners, tasks, rdesc2, list(acc))\n\nparallelStop()\n\nwrite.csv(bmr, \"classification_results.csv\")\n\n\n\n#REGRESION OVER QUANTITY\nreg_learners = list(makeLearner(\"regr.lm\"))\n\nmakeRegrTasks = function(listSets, target){\n  regTasks = list()\n  \n  for(i in c(1:length(listSets))){\n    newTask = makeRegrTask(id = as.character(i), data = subset(listSets[[i]], select = -c(order, revenue_Clean)), target = target)\n    regTasks = append(regTasks, list(newTask))\n  }\n  \n  return(regTasks)\n}\n\n#make reduced sets for the model training\nredSets = list()\nfor(i in c(1:length(sets))){\n  #1) get all with quantity > 0\n  \n  tmp = createDummyFeatures(sets[[i]])\n  \n  tmp = tmp[which(tmp$quantity > 0),]\n  \n  redSets = append(redSets, list(tmp))\n  \n}\n\nregTasks.learn = makeRegrTasks(redSets, \"quantity\")\n\nparallelStartSocket(2, level = \"mlr.resample\")\n\nbmr_reg = benchmark(learners = reg_learners, tasks = regTasks.learn)\n\nparallelStop()\n\n\n\nperformance_combination = function(sets, bmr_class, bmr_rev){\n  #create predict tasks\n  tmp_sets = list()\n  for(i in c(1:length(sets))){\n    tmp = createDummyFeatures(sets[[i]])\n    tmp_sets = append(tmp_sets, list(tmp))\n    \n  }\n  regTasks.pred = makeRegrTasks(tmp_sets, \"quantity\")\n  \n  rev_predictions = list()\n  \n  for(i in bmr_class$results){\n    \n    #Iterating over the tasks\n    for(j in length(i)){\n      tmp = subset(sets[[j]], select = c(revenue_Clean))\n      \n      #reduce it to the size of regr\n      for(k in bmr_reg$results[[j]]){\n        \n        tmp[\"ID\"] = i[[j]]$pred$data$id\n        tmp[\"numericPred\"] = predict(k$models[[1]], regTasks.pred[[j]])$data$response\n        tmp[\"classPred\"] = as.numeric(i[[j]]$pred$data$response)\n        \n      }\n      \n      rev_predictions = append(rev_predictions, list(tmp))\n    }\n  }\n  \n  return(rev_predictions)\n}\ncomb_preds = performance_combination(sets, bmr, bmr_reg)\n\nrevenue_calculation = function(comb_preds){\n  ret = list()\n  for(i in comb_preds){\n    tmp = i\n    tmp[\"revenuePrediction\"] = tmp$numericPred * tmp$classPred\n    ret = append(ret, list(tmp))\n  }\n  \n  return(ret)\n}\n\nrev_preds = revenue_calculation(comb_preds)\n\nrmse_calc = function()\n\n#Final evaluation\n\nrmse_own = function(actual, predicted){\n  error <- actual - predicted\n  rmse = sqrt(mean(error^2))\n  \n  return(rmse)\n}\n\nfor(i in rev_preds){\n  print(rmse_own(i$revenue_Clean, i$revenuePrediction))\n}\n\n\nfinal_ev = data.frame(classifier = character(), regression = character(), rmse = integer())\n\nbmr_reg$results$`1`$regr.lm$models[[1]]\n\n#Final evaluation of the models\n#MSE\n\n#Get confusion matrix of all learner\nlibrary(SDMTools)\nconfusion.matrix(getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$truth, getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$response)\n\nprediction = getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)\ncalculateConfusionMatrix(prediction)\ntable(as.numeric(getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$truth))\ntable(as.numeric(getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$response))\n\nsqldf(\"select CAST(t1.tr AS float) / CAST(count(*) AS float) as acc  from prediction, (select count(*) as tr from prediction where truth = response) as t1\")\n",
    "created" : 1494164912521.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2139439579",
    "id" : "267506E8",
    "lastKnownWriteTime" : 1494164867,
    "last_content_update" : 1494164867,
    "path" : "~/Studium/SS17/DMC17/git/DMC/final.R",
    "project_path" : "final.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}