{
    "collab_server" : "",
    "contents" : "rm(list = ls())\ngc()\nlibrary(\"parallelMap\")\nlibrary(mlr)\nlibrary(sqldf)\nset.seed(42)\noptions(scipen = 999)\n\n\n\n#Installations necessary?\nif(FALSE){\n  install.packages(\"penalized\")\n  install.packages(\"C50\")\n  install.packages(\"randomForest\")\n  install.packages(\"adabag\")\n}\n\nsample = read.csv2(\"01_Data/final_sample.csv\")\n\n#DATA IMPORT AND PREPARATION\noriginalDataImport = function(folder){\n  \n  train_org = read.csv(paste(folder, \"train.csv\", sep = \"\"), sep = \"|\", header = TRUE, dec = \".\")\n  items = read.csv(paste(folder, \"items.csv\", sep = \"\"), sep = \"|\", header = TRUE, dec = \".\")\n  \n  train_org[is.na(train_org)] = 0\n  items[is.na(items)] = \"MISSING\"\n  levels(items$campaignIndex)[1] = \"MISSING\"\n  \n  train_org = subset(sqldf(\"select * from train_org join items on train_org.pid = items.pid\"), select = -c(3))\n  \n  #Remove false predictors\n  train_org = subset(train_org, select = -c(pid, lineID, revenue, click, basket))\n  \n  #factor data\n  train_org.factor = c(\"adFlag\", \"availability\", \"manufacturer\", \"group\", \"content\", \"unit\", \n                       \"genericProduct\", \"salesIndex\", \"category\", \"campaignIndex\", \"order\")\n  \n  for(i in train_org.factor){\n    train_org[i] = as.factor(train_org[[i]])\n  }\n  \n  return(train_org)\n}\nprepDataImport = function(folder){\n  train = read.csv2(paste(folder, \"final_sample.csv\", sep = \"\"))\n  \n  names(train)[names(train)==\"order_Clean\"] = \"order\"\n  \n  #Remove false predictors\n  train = subset(train, select = -c(X, lineID, day_Clean, revenue_Clean, content_Clean))\n  \n  #WEEKDAYS ARE MISSING\n  train.factor_fix = c(\"adFlag_Clean\", \"availability_Clean\", \"order\", \"pharmForm_Clean\", \n                       \"genericProduct_Clean\", \"salesIndex_Clean\", \"missingCompetitorPrice\")\n  \n  train.factor_rem = c(\"manufacturer_Clean\", \"group_Clean\", \"unit_Clean\", \"category_Clean\", \"campaignIndex_Clean\")\n  \n  train.factor = c(train.factor_fix, train.factor_rem)\n  \n  for(i in train.factor){\n    train[i] = as.factor(train[[i]])\n  }\n  \n  return(train)\n}\nsets = list(originalDataImport(\"01_Data/\"), prepDataImport(\"01_Data/\"))\n\nremoveIDLikeFactors = function(listSets, maxNrFactors){\n  #Remove all factorial attributes with nr(factors) > 50\n  for(i in c(1:length(listSets))){\n    test = colnames(listSets[[i]][, sapply(listSets[[i]], is.factor)])\n\n    rem = c(NULL)\n    for(j in test){\n      if(length(table(listSets[[i]][j])) > maxNrFactors)\n        rem = c(rem, j)\n    }\n    \n    listSets[[i]] = listSets[[i]][, (! colnames(listSets[[i]]) %in% rem)]\n  }\n  \n  return(listSets)\n}\nsets = removeIDLikeFactors(sets, 50)\n\n#Sample selection\n#Get uniform sample\nuniformSampling = function(listSets, size){\n  row_sample = sample(rownames(listSets[[1]]), size)\n  \n  for(i in c(1:length(listSets))){\n    row_sample = sample(rownames(listSets[[i]]), size)\n    \n    listSets[[i]] = listSets[[i]][row_sample,]\n  }\n  return(listSets)\n}\nsets = uniformSampling(sets, 20000)\n\n#MODEL PREPARATION\nrdesc = makeResampleDesc(\"CV\", iters = 3)\n#learner selection\nlearners = list(makeLearner(\"classif.OneR\"),\n                makeFeatSelWrapper(\"classif.C50\", resampling = rdesc, control = makeFeatSelControlGA(maxit = 10, mutation.rate = 0.1)))\n\n#makeLearner(\"classif.boosting\")\n#makeFeatSelWrapper(\"classif.randomForest\", resampling = rdesc, control = makeFeatSelControlGA(maxit = 10, mutation.rate = 0.1))\n\n#parameter_sets if necessary\n#getParamSet(\"classif.penalized.lasso\")\n#lasso.learner = makeLearner(\"classif.penalized.lasso\")\n#lasso.learner = setHyperPars(lasso.learner, lambda1 = 10, trace = TRUE)\n#lasso.wrapper = makeFeatSelWrapper(lasso.learner, resampling = rdesc, control = makeFeatSelControlGA(maxit = 10, mutation.rate = 0.1))\n\n#learners = append(learners, list(lasso.wrapper))\n\n#make tasks\nmakeTasks = function(listSets, target, rem = NULL){\n  tasks = list()\n  \n  for(i in c(1:length(listSets))){\n    tasks = append(tasks, list(makeClassifTask(id = as.character(i), data = subset(listSets[[i]], select = - rem), target = target)))\n  }\n  \n  return(tasks)\n}\n\n#Remove quantity for prediction\ntasks = makeTasks(sets, \"order\", rem = list(quantity))\n\n#RESAMPLING / TESTING DECSISION\nrdesc2 = makeResampleDesc(\"CV\", iters = 5)\n\n#EVALUATION\n#parralization\n#parallelStartBatchJobs()\nparallelStartSocket(2, level = \"mlr.resample\")\n#Setting up a benchmarking experiment\n\nbmr = benchmark(learners, tasks, rdesc2, list(acc, fpr, fnr))\n\nparallelStop()\nwrite.csv(bmr, \"test.csv\")\n\n\n#PARALIZATION\n\n\n#Final evaluation of the models\n#MSE\n\n#Get confusion matrix of all learner\nlibrary(SDMTools)\nconfusion.matrix(getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$truth, getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$response)\n\nprediction = getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)\ncalculateConfusionMatrix(prediction)\ntable(as.numeric(getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$truth))\ntable(as.numeric(getBMRPredictions(bmr, learner.ids = \"classif.OneR\", as.df = TRUE)$response))\n\nsqldf(\"select CAST(t1.tr AS float) / CAST(count(*) AS float) as acc  from prediction, (select count(*) as tr from prediction where truth = response) as t1\")\n",
    "created" : 1494064457647.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1117410087",
    "id" : "76D960A8",
    "lastKnownWriteTime" : 1494000664,
    "last_content_update" : 1494065198368,
    "path" : "~/project/DMC/final.R",
    "project_path" : "final.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}